{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# LangFuseë¥¼ ì‚¬ìš©í•œ ê´€ì°°ì„±ê³¼ RAGASë¥¼ ì‚¬ìš©í•œ í‰ê°€ë¡œ Strands Agent í‰ê°€í•˜ê¸°\n",
    "\n",
    "## ê°œìš”\n",
    "ì´ ì˜ˆì œì—ì„œëŠ” ê´€ì°°ì„± ë° í‰ê°€ ê¸°ëŠ¥ì„ ê°–ì¶˜ ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. [Langfuse](https://langfuse.com/)ë¥¼ í™œìš©í•˜ì—¬ Strands Agent ì¶”ì ì„ ì²˜ë¦¬í•˜ê³  [Ragas](https://www.ragas.io/) ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ì£¼ìš” ì´ˆì ì€ SDKì—ì„œ ìƒì„±í•œ ì¶”ì ì„ ì‚¬ìš©í•˜ì—¬ Agentê°€ ìƒì„±í•œ ì‘ë‹µì˜ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "Strands AgentsëŠ” LangFuseì™€ì˜ ê´€ì°°ì„±ì— ëŒ€í•œ ê¸°ë³¸ ì œê³µ ì§€ì›ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” Langfuseì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³ , Ragasì—ì„œ í•„ìš”í•œ ë³€í™˜ì„ ì ìš©í•˜ê³ , í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ê³ , ë§ˆì§€ë§‰ìœ¼ë¡œ ì ìˆ˜ë¥¼ ì¶”ì ì— ë‹¤ì‹œ ì—°ê²°í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì¶”ì ê³¼ ì ìˆ˜ë¥¼ í•œ ê³³ì— ë°°ì¹˜í•˜ë©´ ì‹¬ì¸µ ë¶„ì„, ì¶”ì„¸ ë¶„ì„ ë° ì§€ì†ì ì¸ ê°œì„ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "## ì—ì´ì „íŠ¸ ì„¸ë¶€ ì •ë³´\n",
    "<div style=\"float: left; margin-right: 20px;\">\n",
    "    \n",
    "|ê¸°ëŠ¥                |ì„¤ëª…                                                |\n",
    "|--------------------|---------------------------------------------------|\n",
    "|ì‚¬ìš©ëœ ê¸°ë³¸ ë„êµ¬     |current_time, retrieve                             |\n",
    "|ìƒì„±ëœ ì»¤ìŠ¤í…€ ë„êµ¬   |create_booking, get_booking_details, delete_booking|\n",
    "|ì—ì´ì „íŠ¸ êµ¬ì¡°       |ë‹¨ì¼ ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜                               |\n",
    "|ì‚¬ìš©ëœ AWS ì„œë¹„ìŠ¤   |Amazon Bedrock Knowledge Base, Amazon DynamoDB    |\n",
    "|í†µí•©                |ê´€ì°°ì„±ì„ ìœ„í•œ LangFuse ë° ê´€ì°°ì„ ìœ„í•œ Ragas         |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## ì•„í‚¤í…ì²˜\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture.png\" width=\"75%\" />\n",
    "</div>\n",
    "\n",
    "## ì£¼ìš” ê¸°ëŠ¥\n",
    "- Langfuseì—ì„œ Strands ì—ì´ì „íŠ¸ ìƒí˜¸ ì‘ìš© ì¶”ì ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. ì´ëŸ¬í•œ ì¶”ì ì„ ì˜¤í”„ë¼ì¸ìœ¼ë¡œ ì €ì¥í•˜ê³  Langfuse ì—†ì´ ì—¬ê¸°ì—ì„œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "- ì—ì´ì „íŠ¸, ë„êµ¬ ë° RAGì— ëŒ€í•œ ì „ë¬¸ ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”ë¥¼ í‰ê°€í•©ë‹ˆë‹¤\n",
    "- ì™„ì „í•œ í”¼ë“œë°± ë£¨í”„ë¥¼ ìœ„í•´ í‰ê°€ ì ìˆ˜ë¥¼ Langfuseë¡œ ë‹¤ì‹œ í‘¸ì‹œí•©ë‹ˆë‹¤\n",
    "- ë‹¨ì¼ í„´(ì»¨í…ìŠ¤íŠ¸ í¬í•¨) ë° ë©€í‹° í„´ ëŒ€í™”ë¥¼ ëª¨ë‘ í‰ê°€í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## ì„¤ì • ë° ì‚¬ì „ ìš”êµ¬ì‚¬í•­\n",
    "\n",
    "### ì‚¬ì „ ìš”êµ¬ì‚¬í•­\n",
    "* Python 3.10+\n",
    "* AWS ê³„ì •\n",
    "* Amazon Bedrockì—ì„œ í™œì„±í™”ëœ Anthropic Claude 3.7\n",
    "* Amazon Bedrock Knowledge Base, Amazon S3 ë²„í‚· ë° Amazon DynamoDBë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” ê¶Œí•œì´ ìˆëŠ” IAM ì—­í• \n",
    "* LangFuse í‚¤\n",
    "\n",
    "ì´ì œ Strands Agentì— í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê² ìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install --upgrade --force-reinstall -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "ì´ì œ ìµœì‹  ë²„ì „ì˜ Strands Agents Toolsë¥¼ ì‹¤í–‰í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install strands-agents-tools>=0.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "Amazon Bedrock Knowledge Base ë° DynamoDB í…Œì´ë¸” ë°°í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deploy Amazon Bedrock Knowledge Base and Amazon DynamoDB instance\n",
    "!sh deploy_prereqs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### ì¢…ì†ì„± íŒ¨í‚¤ì§€ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "ì´ì œ ì¢…ì†ì„± íŒ¨í‚¤ì§€ë¥¼ ê°€ì ¸ì˜¤ê² ìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from langfuse import Langfuse\n",
    "from ragas.metrics import (\n",
    "    ContextRelevance,\n",
    "    ResponseGroundedness, \n",
    "    AspectCritic,\n",
    "    RubricsScore\n",
    ")\n",
    "from ragas.dataset_schema import (\n",
    "    SingleTurnSample,\n",
    "    MultiTurnSample,\n",
    "    EvaluationDataset\n",
    ")\n",
    "from ragas import evaluate\n",
    "from langchain_aws import ChatBedrock\n",
    "from ragas.llms import LangchainLLMWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "#### Strands Agentsê°€ LangFuse ì¶”ì ì„ ë‚´ë³´ë‚´ë„ë¡ ì„¤ì •\n",
    "ì—¬ê¸°ì„œ ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” Strands Agentsê°€ LangFuseë¡œ ì¶”ì ì„ ë‚´ë³´ë‚´ë„ë¡ ì„¤ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
    "public_key = \"<YOUR_PUBLIC_KEY>\" \n",
    "secret_key = \"<YOUR_SECRET_KEY>\"\n",
    "\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # ğŸ‡ªğŸ‡º EU region\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # ğŸ‡ºğŸ‡¸ US region\n",
    "\n",
    "# Set up endpoint\n",
    "otel_endpoint = str(os.environ.get(\"LANGFUSE_HOST\")) + \"/api/public/otel/v1/traces\"\n",
    "\n",
    "# Create authentication token:\n",
    "import base64\n",
    "auth_token = base64.b64encode(f\"{public_key}:{secret_key}\".encode()).decode()\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = otel_endpoint\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {auth_token}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "#### ì—ì´ì „íŠ¸ ìƒì„±\n",
    "\n",
    "ì´ ì—°ìŠµì˜ ëª©ì ì„ ìœ„í•´ ì´ë¯¸ ë„êµ¬ë¥¼ Python ëª¨ë“ˆ íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤. ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ì´ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  `sh deploy_prereqs.sh`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ ë°°í¬í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "ì´ì œ `03-aws-serviceì™€ ì—°ê²°í•˜ëŠ” agent ë§Œë“¤ê¸°`ì˜ ë ˆìŠ¤í† ë‘ ìƒ˜í”Œì„ ì‚¬ìš©í•˜ê³  LangFuseì™€ ì—°ê²°í•˜ì—¬ ì¼ë¶€ ì¶”ì ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_booking_details, delete_booking, create_booking\n",
    "from strands_tools import retrieve, current_time\n",
    "from strands import Agent, tool\n",
    "from strands.models.bedrock import BedrockModel\n",
    "import boto3\n",
    "\n",
    "system_prompt = \"\"\"ë‹¹ì‹ ì€ \"ë ˆìŠ¤í† ë‘ ë„ìš°ë¯¸\"ë¡œ, ë‹¤ì–‘í•œ ë ˆìŠ¤í† ë‘ì—ì„œ ê³ ê°ì˜ í…Œì´ë¸” ì˜ˆì•½ì„ ë•ëŠ” ë ˆìŠ¤í† ë‘ ë³´ì¡°ì…ë‹ˆë‹¤. ë©”ë‰´ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê±°ë‚˜, ìƒˆ ì˜ˆì•½ì„ ìƒì„±í•˜ê±°ë‚˜, ê¸°ì¡´ ì˜ˆì•½ì˜ ì„¸ë¶€ ì •ë³´ë¥¼ í™•ì¸í•˜ê±°ë‚˜, ê¸°ì¡´ ì˜ˆì•½ì„ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•­ìƒ ì •ì¤‘í•˜ê²Œ ë‹µë³€í•˜ë©° ë‹µë³€ì— ìì‹ ì˜ ì´ë¦„(ë ˆìŠ¤í† ë‘ ë„ìš°ë¯¸)ì„ ì–¸ê¸‰í•˜ì„¸ìš”. \n",
    "  ìƒˆë¡œìš´ ëŒ€í™” ì‹œì‘ ì‹œ ì ˆëŒ€ ì´ë¦„ ìƒëµí•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ë‹µë³€í•  ìˆ˜ ì—†ëŠ” ì§ˆë¬¸ì„ ë°›ì„ ê²½ìš°,\n",
    "  ë” ë‚˜ì€ ë§ì¶¤í˜• ì„œë¹„ìŠ¤ë¥¼ ìœ„í•´ ë‹¤ìŒ ì „í™”ë²ˆí˜¸ë¥¼ ì•ˆë‚´í•´ ì£¼ì„¸ìš”: +1 999 999 99 9999.\n",
    "  \n",
    "  ê³ ê° ë¬¸ì˜ì— ë‹µë³€í•˜ëŠ” ë° ìœ ìš©í•œ ì •ë³´:\n",
    "  ë ˆìŠ¤í† ë‘ í—¬í¼ ì£¼ì†Œ: 101W 87th Street, 100024, New York, New York\n",
    "  ê¸°ìˆ  ì§€ì› ë¬¸ì˜ ì‹œì—ë§Œ ë ˆìŠ¤í† ë‘ í—¬í¼ì— ì—°ë½í•˜ì‹­ì‹œì˜¤.\n",
    "  ì˜ˆì•½ ì „ í•´ë‹¹ ë ˆìŠ¤í† ë‘ì´ ì €í¬ ë ˆìŠ¤í† ë‘ ë””ë ‰í† ë¦¬ì— ë“±ë¡ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.\n",
    "  \n",
    "  ë ˆìŠ¤í† ë‘ ë° ë©”ë‰´ ê´€ë ¨ ë¬¸ì˜ì—ëŠ” ì§€ì‹ ê¸°ë°˜ ê²€ìƒ‰ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì‹­ì‹œì˜¤.\n",
    "  ì²« ëŒ€í™” ì‹œ ë°˜ë“œì‹œ ì¸ì‚¬ ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ì‚¬í•˜ì‹­ì‹œì˜¤.\n",
    "  \n",
    "  ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•œ ì¼ë ¨ì˜ ê¸°ëŠ¥ì´ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "  ì§ˆë¬¸ì— ë‹µë³€í•  ë•ŒëŠ” í•­ìƒ ì•„ë˜ ì§€ì¹¨ì„ ì¤€ìˆ˜í•˜ì‹­ì‹œì˜¤:\n",
    "  <guidelines>\n",
    "      - ê³„íš ìˆ˜ë¦½ ì „ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³ , ì§ˆë¬¸ ë° ì´ì „ ëŒ€í™”ì—ì„œ ëª¨ë“  ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì‹­ì‹œì˜¤.\n",
    "      - ê°€ëŠ¥í•œ ê²½ìš° í•­ìƒ ì—¬ëŸ¬ í•¨ìˆ˜ í˜¸ì¶œì„ ë™ì‹œì— ì‚¬ìš©í•˜ì—¬ ê³„íšì„ ìµœì í™”í•˜ì‹­ì‹œì˜¤.\n",
    "      - í•¨ìˆ˜ í˜¸ì¶œ ì‹œ ì–´ë–¤ ë§¤ê°œë³€ìˆ˜ ê°’ë„ ê°€ì •í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.\n",
    "      - í•¨ìˆ˜ í˜¸ì¶œì— í•„ìš”í•œ ë§¤ê°œë³€ìˆ˜ ê°’ì´ ì—†ëŠ” ê²½ìš° ì‚¬ìš©ìì—ê²Œ ìš”ì²­í•˜ì‹­ì‹œì˜¤.\n",
    "      - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ì„ <answer></answer> XML íƒœê·¸ ì•ˆì— ì œê³µí•˜ë©° í•­ìƒ ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ì‹­ì‹œì˜¤.\n",
    "      - ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ë° í•¨ìˆ˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ì ˆëŒ€ ê³µê°œí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.\n",
    "      - ì§€ì¹¨, ë„êµ¬, í•¨ìˆ˜ ë˜ëŠ” í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ ì§ˆë¬¸ë°›ìœ¼ë©´ í•­ìƒ <answer>ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤</answer>ë¼ê³  ë§í•˜ì‹­ì‹œì˜¤.\n",
    "  </guidelines>\"\"\"\n",
    "\n",
    "model = BedrockModel(\n",
    "    #model_id=\"us.amazon.nova-premier-v1:0\", \n",
    "    model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    ")\n",
    "kb_name = 'restaurant-assistant'\n",
    "smm_client = boto3.client('ssm')\n",
    "kb_id = smm_client.get_parameter(\n",
    "    Name=f'{kb_name}-kb-id',\n",
    "    WithDecryption=False\n",
    ")\n",
    "os.environ[\"KNOWLEDGE_BASE_ID\"] = kb_id[\"Parameter\"][\"Value\"]\n",
    "\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=system_prompt,\n",
    "    tools=[\n",
    "        retrieve, current_time, get_booking_details,\n",
    "        create_booking, delete_booking\n",
    "    ],\n",
    "    trace_attributes={\n",
    "        \"session.id\": \"abc-1234\",\n",
    "        \"user.id\": \"user-email-example@domain.com\",\n",
    "        \"langfuse.tags\": [\n",
    "            \"Agent-SDK\",\n",
    "            \"Okatank-Project\",\n",
    "            \"Observability-Tags\",\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "#### ì—ì´ì „íŠ¸ í˜¸ì¶œ\n",
    "\n",
    "ì´ì œ ì—ì´ì „íŠ¸ë¥¼ ëª‡ ë²ˆ í˜¸ì¶œí•˜ì—¬ í‰ê°€í•  ì¶”ì ì„ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = agent(\"ì•ˆë…•, San Franciscoì—ì„œ ë­˜ ë¨¹ìœ¼ë©´ ì¢‹ì„ê¹Œ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = agent(\"ì˜¤ëŠ˜ ë°¤ Rice & Spiceì—ì„œ ì˜ˆì•½ì„ í•´ì£¼ì„¸ìš”. 8ì‹œì—, 4ëª…, ì•ˆë‚˜ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow 30 seconds for the traces to be available in Langfuse:\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "# í‰ê°€ ì‹œì‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Langfuse ì—°ê²° ì„¤ì •\n",
    "\n",
    "LangfuseëŠ” LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ì„ ì¶”ì í•˜ê³  ë¶„ì„í•˜ê¸° ìœ„í•œ í”Œë«í¼ì…ë‹ˆë‹¤. ê³µê°œ í‚¤ë¥¼ ì–»ìœ¼ë ¤ë©´ [LangFuse cloud](https://us.cloud.langfuse.com)ì— ë“±ë¡í•´ì•¼ í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse = Langfuse(\n",
    "    public_key=public_key,\n",
    "    secret_key=secret_key,\n",
    "    host=\"https://us.cloud.langfuse.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## RAGAS í‰ê°€ë¥¼ ìœ„í•œ Judge LLM ëª¨ë¸ ì„¤ì •\n",
    "\n",
    "Judgeë¡œì„œì˜ LLMì€ ì—ì´ì „íŠ¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ í‰ê°€í•˜ëŠ” ì¼ë°˜ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ í‰ê°€ìë¡œ ì„¤ì •í•  ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤. Ragasë¥¼ ì‚¬ìš©í•˜ë©´ ëª¨ë“  ëª¨ë¸ì„ í‰ê°€ìë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì˜ˆì œì—ì„œëŠ” Amazon Bedrockì„ í†µí•´ Claude 3.7 Sonnetì„ ì‚¬ìš©í•˜ì—¬ í‰ê°€ ë©”íŠ¸ë¦­ì„ êµ¬ë™í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup LLM for RAGAS evaluations\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "bedrock_llm = ChatBedrock(\n",
    "    model_id=\"us.amazon.nova-premier-v1:0\", \n",
    "    region_name=region\n",
    ")\n",
    "evaluator_llm = LangchainLLMWrapper(bedrock_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Ragas ë©”íŠ¸ë¦­ ì •ì˜\n",
    "RagasëŠ” AI ì—ì´ì „íŠ¸ì˜ ëŒ€í™” ë° ì˜ì‚¬ ê²°ì • ê¸°ëŠ¥ì„ í‰ê°€í•˜ë„ë¡ ì„¤ê³„ëœ ì—ì´ì „íŠ¸ ë©”íŠ¸ë¦­ ëª¨ìŒì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œì—ì„œ ì—ì´ì „íŠ¸ê°€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ í‰ê°€í•˜ëŠ” ê²ƒë¿ë§Œ ì•„ë‹ˆë¼ ê³ ê° ë§Œì¡±ë„ í–¥ìƒ, ìƒí–¥ íŒë§¤ ê¸°íšŒ ì´‰ì§„ ë˜ëŠ” ë¸Œëœë“œ ìŒì„± ìœ ì§€ì™€ ê°™ì€ íŠ¹ì • ì§ˆì  ë˜ëŠ” ì „ëµì  ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ í‰ê°€í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê´‘ë²”ìœ„í•œ í‰ê°€ ìš”êµ¬ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´ Ragas í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ë©´ ì‚¬ìš©ìê°€ **ì»¤ìŠ¤í…€ í‰ê°€ ë©”íŠ¸ë¦­**ì„ ì •ì˜í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ íŒ€ì´ ë¹„ì¦ˆë‹ˆìŠ¤ ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…ìŠ¤íŠ¸ì— ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì„ ê¸°ë°˜ìœ¼ë¡œ í‰ê°€ë¥¼ ë§ì¶¤í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì»¤ìŠ¤í…€ ê°€ëŠ¥í•˜ê³  ìœ ì—°í•œ ë©”íŠ¸ë¦­ ì¤‘ ë‘ ê°€ì§€ëŠ” **Aspect Critic Metric** ë° **Rubric Score Metric**ì…ë‹ˆë‹¤.\n",
    "\n",
    "- **Aspect Criteria** ë©”íŠ¸ë¦­ì€ ì—ì´ì „íŠ¸ì˜ ì‘ë‹µì´ **íŠ¹ì • ì‚¬ìš©ì ì •ì˜ ê¸°ì¤€**ì„ ì¶©ì¡±í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” **ì´ì§„ í‰ê°€ ë©”íŠ¸ë¦­**ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ì¤€ì€ ëŒ€ì•ˆ ì œê³µ, ìœ¤ë¦¬ ì§€ì¹¨ ì¤€ìˆ˜ ë˜ëŠ” ê³µê° í‘œí˜„ê³¼ ê°™ì€ ì—ì´ì „íŠ¸ ë™ì‘ì˜ ë°”ëŒì§í•œ ì¸¡ë©´ì„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- **Rubric Score** ë©”íŠ¸ë¦­ì€ ë‹¨ìˆœí•œ ì´ì§„ ì¶œë ¥ì´ ì•„ë‹Œ **ì´ì‚° ë‹¤ë‹¨ê³„ ì ìˆ˜ ë§¤ê¸°ê¸°**ë¥¼ í—ˆìš©í•˜ì—¬ í•œ ê±¸ìŒ ë” ë‚˜ì•„ê°‘ë‹ˆë‹¤. ì´ ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•˜ë©´ ë£¨ë¸Œë¦­(ê°ê° ì„¤ëª… ë˜ëŠ” ìš”êµ¬ ì‚¬í•­ì´ ìˆ˜ë°˜ë˜ëŠ” ê³ ìœ í•œ ì ìˆ˜ ì§‘í•©)ì„ ì •ì˜í•œ ë‹¤ìŒ LLMì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì˜ í’ˆì§ˆ ë˜ëŠ” íŠ¹ì„±ì„ ê°€ì¥ ì˜ ë°˜ì˜í•˜ëŠ” ì ìˆ˜ë¥¼ ê²°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì—ì´ì „íŠ¸ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ì´ì œ ëª‡ ê°€ì§€ **AspectCritic** ë©”íŠ¸ë¦­ì„ ì„¤ì •í•˜ê² ìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_completeness = AspectCritic(\n",
    "    name=\"Request Completeness\",\n",
    "    llm=evaluator_llm,\n",
    "    definition=(\n",
    "        \"ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©ìì˜ ëª¨ë“  ìš”ì²­ì„ ëˆ„ë½ ì—†ì´ ì™„ì „íˆ ì¶©ì¡±ì‹œí‚¤ë©´ 1ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\n",
    "        \"ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# AIì˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì´ ì›í•˜ëŠ” ë¸Œëœë“œ í†¤ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í‰ê°€í•˜ëŠ” ì§€í‘œ\n",
    "brand_tone = AspectCritic(\n",
    "    name=\"Brand Voice Metric\",\n",
    "    llm=evaluator_llm,\n",
    "    definition=(\n",
    "        \"AIì˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì´ ì¹œê·¼í•˜ê³ , ì ‘ê·¼í•˜ê¸° ì‰¬ìš°ë©°, ë„ì›€ì´ ë˜ê³ , ëª…í™•í•˜ê³ , ê°„ê²°í•  ê²½ìš° 1ì„ ë°˜í™˜í•©ë‹ˆë‹¤; \"\n",
    "        \"ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\n",
    "    ),)\n",
    "\n",
    "\n",
    "# ë„êµ¬ ì‚¬ìš© íš¨ê³¼ì„± ì§€í‘œ\n",
    "tool_usage_effectiveness = AspectCritic(\n",
    "    name=\"Tool Usage Effectiveness\",\n",
    "    llm=evaluator_llm,\n",
    "    definition=(\n",
    "        \"ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì¶©ì¡±ì‹œí‚¤ê¸° ìœ„í•´ ì—ì´ì „íŠ¸ê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•œ ê²½ìš° 1ì„ ë°˜í™˜í•©ë‹ˆë‹¤. \"\n",
    "        \"(ì˜ˆ: ë©”ë‰´ ì§ˆë¬¸ì—ëŠ” retrieve, ì‹œê°„ ì§ˆë¬¸ì—ëŠ” current_time ì‚¬ìš©). \"\n",
    "        \"ì—ì´ì „íŠ¸ê°€ ì ì ˆí•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì§€ ëª»í–ˆê±°ë‚˜ ë¶ˆí•„ìš”í•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•œ ê²½ìš° 0ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\n",
    "    ),)\n",
    "\n",
    "\n",
    "# ë„êµ¬ ì„ íƒ ì ì ˆì„± ì§€í‘œ\n",
    "tool_selection_appropriateness = AspectCritic(\n",
    "    name=\"Tool Selection Appropriateness\",\n",
    "    llm=evaluator_llm,\n",
    "    definition=(\n",
    "        \"ì—ì´ì „íŠ¸ê°€ ì‘ì—…ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•œ ê²½ìš° 1ì„ ë°˜í™˜í•©ë‹ˆë‹¤. \"\n",
    "        \"ë” ë‚˜ì€ ë„êµ¬ ì„ íƒì´ ê°€ëŠ¥í–ˆê±°ë‚˜ ë¶ˆí•„ìš”í•œ ë„êµ¬ê°€ ì„ íƒëœ ê²½ìš° 0ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "ì´ì œ ìŒì‹ ì¶”ì²œì˜ ë¹„ì´ì§„ íŠ¹ì„±ì„ ëª¨ë¸ë§í•˜ê¸° ìœ„í•´ **RubricsScore**ë„ ì„¤ì •í•˜ê² ìŠµë‹ˆë‹¤. ì´ ë©”íŠ¸ë¦­ì— ëŒ€í•´ 3ê°œì˜ ì ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤:\n",
    "\n",
    "- **-1** ê³ ê°ì´ ìš”ì²­í•œ í•­ëª©ì´ ë©”ë‰´ì— ì—†ê³  ì¶”ì²œì´ ì´ë£¨ì–´ì§€ì§€ ì•Šì€ ê²½ìš°\n",
    "- **0** ê³ ê°ì´ ìš”ì²­í•œ í•­ëª©ì´ ë©”ë‰´ì— ìˆê±°ë‚˜ ëŒ€í™”ì— ìŒì‹ ë˜ëŠ” ë©”ë‰´ ë¬¸ì˜ê°€ í¬í•¨ë˜ì§€ ì•Šì€ ê²½ìš°\n",
    "- **1** ê³ ê°ì´ ìš”ì²­í•œ í•­ëª©ì´ ë©”ë‰´ì— ì—†ê³  ì¶”ì²œì´ ì œê³µëœ ê²½ìš°.\n",
    "\n",
    "\n",
    "ì´ ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•˜ë©´ ì˜ëª»ëœ ë™ì‘ì— ìŒìˆ˜ ê°’ì„ ì œê³µí•˜ê³  ì˜¬ë°”ë¥¸ ë™ì‘ì— ì–‘ìˆ˜ ê°’ì„ ì œê³µí•˜ë©° í‰ê°€ê°€ ì ìš©ë˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ëŠ” 0ì„ ì œê³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubrics = {\n",
    "    \"score-1_description\": (\n",
    "        \"\"\"ê³ ê°ì´ ìš”ì²­í•œ ë©”ë‰´ í•­ëª©ì´ ë©”ë‰´ì— ì—†ìœ¼ë©°, ì–´ë– í•œ ì¶”ì²œë„ ì´ë£¨ì–´ì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\"\"\n",
    "    ),\n",
    "    \"score0_description\": (\n",
    "        \"ê³ ê°ì´ ìš”ì²­í•œ ë©”ë‰´ í•­ëª©ì´ ë©”ë‰´ì— ìˆê±°ë‚˜, \"\n",
    "        \"ë˜ëŠ” ëŒ€í™” ë‚´ìš©ì— ìŒì‹ì´ë‚˜ ë©”ë‰´ ê´€ë ¨ ë¬¸ì˜ê°€ ì „í˜€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤(ì˜ˆ: ì˜ˆì•½, ì·¨ì†Œ).\"\n",
    "        \"ì´ ì ìˆ˜ëŠ” ì¶”ì²œì´ ì œê³µë˜ì—ˆëŠ”ì§€ ì—¬ë¶€ì™€ ë¬´ê´€í•˜ê²Œ ì ìš©ë©ë‹ˆë‹¤.\"\n",
    "    ),\n",
    "    \"score1_description\": (\n",
    "        \"ê³ ê°ì´ ìš”ì²­í•œ ë©”ë‰´ í•­ëª©ì´ ë©”ë‰´ì— ì—†ìœ¼ë©° \"\n",
    "        \"ì¶”ì²œì´ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤.\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "recommendations = RubricsScore(rubrics=rubrics, llm=evaluator_llm, name=\"Recommendations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "#### ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG) í‰ê°€\n",
    "\n",
    "ì™¸ë¶€ ì§€ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ ì‘ë‹µì„ ìƒì„±í•  ë•Œ RAG êµ¬ì„± ìš”ì†Œë¥¼ í‰ê°€í•˜ëŠ” ê²ƒì€ ì—ì´ì „íŠ¸ê°€ ì •í™•í•˜ê³  ê´€ë ¨ì„± ìˆìœ¼ë©° ì»¨í…ìŠ¤íŠ¸ì— ê¸°ë°˜í•œ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ ë³´ì¥í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤. Ragas í”„ë ˆì„ì›Œí¬ì—ì„œ ì œê³µí•˜ëŠ” RAG ë©”íŠ¸ë¦­ì€ ê²€ìƒ‰ëœ ë¬¸ì„œì˜ í’ˆì§ˆê³¼ ìƒì„±ëœ ì¶œë ¥ì˜ ì¶©ì‹¤ì„±ì„ ëª¨ë‘ ì¸¡ì •í•˜ì—¬ RAG ì‹œìŠ¤í…œì˜ íš¨ê³¼ë¥¼ í‰ê°€í•˜ë„ë¡ íŠ¹ë³„íˆ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ ë˜ëŠ” ê¸°ë°˜ì˜ ì‹¤íŒ¨ëŠ” ì—ì´ì „íŠ¸ê°€ ì¼ê´€ë˜ê±°ë‚˜ ìœ ì°½í•´ ë³´ì´ë”ë¼ë„ í™˜ê°ë˜ê±°ë‚˜ ì˜¤í•´ì˜ ì†Œì§€ê°€ ìˆëŠ” ì‘ë‹µìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì—ì´ì „íŠ¸ê°€ Knowledge Baseì—ì„œ ê²€ìƒ‰í•œ ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ ì˜ í™œìš©í•˜ëŠ”ì§€ í‰ê°€í•˜ê¸° ìœ„í•´ Ragasì—ì„œ ì œê³µí•˜ëŠ” RAG í‰ê°€ ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ì—¬ê¸°](https://docs.ragas.io/en/latest/concepts/metrics/available_metrics/)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "\n",
    "ì´ ì˜ˆì œì—ì„œëŠ” ë‹¤ìŒ RAG ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:\n",
    "\n",
    "- [ContextRelevance](https://docs.ragas.io/en/latest/concepts/metrics/available_metrics/nvidia_metrics/#context-relevance): ì´ì¤‘ LLM íŒë‹¨ì„ í†µí•´ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ì—¬ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ê°€ ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì²˜ë¦¬í•˜ëŠ”ì§€ ì¸¡ì •í•©ë‹ˆë‹¤.\n",
    "- [ResponseGroundedness](https://docs.ragas.io/en/latest/concepts/metrics/available_metrics/nvidia_metrics/#response-groundedness): ì‘ë‹µì˜ ê° ì£¼ì¥ì´ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ ì§€ì›ë˜ê±°ë‚˜ \"ê¸°ë°˜\"ì´ ë˜ëŠ” ì •ë„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG-specific metrics for knowledge base evaluations\n",
    "context_relevance = ContextRelevance(llm=evaluator_llm)\n",
    "response_groundedness = ResponseGroundedness(llm=evaluator_llm)\n",
    "\n",
    "metrics=[context_relevance, response_groundedness]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## í—¬í¼ í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "ì´ì œ í‰ê°€ ë©”íŠ¸ë¦­ì„ ì •ì˜í–ˆìœ¼ë¯€ë¡œ í‰ê°€ë¥¼ ìœ„í•´ ì¶”ì  êµ¬ì„± ìš”ì†Œë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í—¬í¼ í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "#### ì¶”ì ì—ì„œ êµ¬ì„± ìš”ì†Œ ì¶”ì¶œ\n",
    "\n",
    "ì´ì œ í‰ê°€ë¥¼ ìœ„í•´ Langfuse ì¶”ì ì—ì„œ í•„ìš”í•œ êµ¬ì„± ìš”ì†Œë¥¼ ì¶”ì¶œí•˜ëŠ” ëª‡ ê°€ì§€ í•¨ìˆ˜ë¥¼ ë§Œë“¤ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_span_components(trace):\n",
    "    \"\"\"Extract user queries, agent responses, retrieved contexts \n",
    "    and tool usage from a Langfuse trace\"\"\"\n",
    "    user_inputs = []\n",
    "    agent_responses = []\n",
    "    retrieved_contexts = []\n",
    "    tool_usages = []\n",
    "\n",
    "    # Get basic information from trace\n",
    "    if hasattr(trace, 'input') and trace.input is not None:\n",
    "        if isinstance(trace.input, dict) and 'args' in trace.input:\n",
    "            if trace.input['args'] and len(trace.input['args']) > 0:\n",
    "                user_inputs.append(str(trace.input['args'][0]))\n",
    "        elif isinstance(trace.input, str):\n",
    "            user_inputs.append(trace.input)\n",
    "        else:\n",
    "            user_inputs.append(str(trace.input))\n",
    "\n",
    "    if hasattr(trace, 'output') and trace.output is not None:\n",
    "        if isinstance(trace.output, str):\n",
    "            agent_responses.append(trace.output)\n",
    "        else:\n",
    "            agent_responses.append(str(trace.output))\n",
    "\n",
    "    # Try to get contexts from observations and tool usage details\n",
    "    try:\n",
    "        for obsID in trace.observations:\n",
    "            print (f\"Getting Observation {obsID}\")\n",
    "            observations = langfuse.api.observations.get(obsID)\n",
    "\n",
    "            for obs in observations:\n",
    "                # Extract tool usage information\n",
    "                if hasattr(obs, 'name') and obs.name:\n",
    "                    tool_name = str(obs.name)\n",
    "                    tool_input = obs.input if hasattr(obs, 'input') and obs.input else None\n",
    "                    tool_output = obs.output if hasattr(obs, 'output') and obs.output else None\n",
    "                    tool_usages.append({\n",
    "                        \"name\": tool_name,\n",
    "                        \"input\": tool_input,\n",
    "                        \"output\": tool_output\n",
    "                    })\n",
    "                    # Specifically capture retrieved contexts\n",
    "                    if 'retrieve' in tool_name.lower() and tool_output:\n",
    "                        retrieved_contexts.append(str(tool_output))\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching observations: {e}\")\n",
    "\n",
    "    # Extract tool names from metadata if available\n",
    "    if hasattr(trace, 'metadata') and trace.metadata:\n",
    "        if 'attributes' in trace.metadata:\n",
    "            attributes = trace.metadata['attributes']\n",
    "            if 'agent.tools' in attributes:\n",
    "                available_tools = attributes['agent.tools']\n",
    "    return {\n",
    "        \"user_inputs\": user_inputs,\n",
    "        \"agent_responses\": agent_responses,\n",
    "        \"retrieved_contexts\": retrieved_contexts,\n",
    "        \"tool_usages\": tool_usages,\n",
    "        \"available_tools\": available_tools if 'available_tools' in locals() else []\n",
    "    }\n",
    "\n",
    "\n",
    "def fetch_traces(batch_size=10, lookback_hours=24, tags=None):\n",
    "    \"\"\"Fetch traces from Langfuse based on specified criteria\"\"\"\n",
    "    # Calculate time range\n",
    "    end_time = datetime.now()\n",
    "    start_time = end_time - timedelta(hours=lookback_hours)\n",
    "    print(f\"Fetching traces from {start_time} to {end_time}\")\n",
    "    # Fetch traces\n",
    "    if tags:\n",
    "        traces = langfuse.api.trace.list(\n",
    "            limit=batch_size,\n",
    "            tags=tags,\n",
    "            from_timestamp=start_time,\n",
    "            to_timestamp=end_time\n",
    "        ).data\n",
    "    else:\n",
    "        traces = langfuse.api.trace.list(\n",
    "            limit=batch_size,\n",
    "            from_timestamp=start_time,\n",
    "            to_timestamp=end_time\n",
    "        ).data\n",
    "    \n",
    "    print(f\"Fetched {len(traces)} traces\")\n",
    "    return traces\n",
    "\n",
    "def process_traces(traces):\n",
    "    \"\"\"Process traces into samples for RAGAS evaluation\"\"\"\n",
    "    single_turn_samples = []\n",
    "    multi_turn_samples = []\n",
    "    trace_sample_mapping = []\n",
    "    \n",
    "    for trace in traces:\n",
    "        # Extract components\n",
    "        components = extract_span_components(trace)\n",
    "        \n",
    "        # Add tool usage information to the trace for evaluation\n",
    "        tool_info = \"\"\n",
    "        if components[\"tool_usages\"]:\n",
    "            tool_info = \"Tools used: \" + \", \".join([t[\"name\"] for t in components[\"tool_usages\"] if \"name\" in t])\n",
    "            \n",
    "        # Convert to RAGAS samples\n",
    "        if components[\"user_inputs\"]:\n",
    "            # For single turn with context, create a SingleTurnSample\n",
    "            if components[\"retrieved_contexts\"]:\n",
    "                single_turn_samples.append(\n",
    "                    SingleTurnSample(\n",
    "                        user_input=components[\"user_inputs\"][0],\n",
    "                        response=components[\"agent_responses\"][0] if components[\"agent_responses\"] else \"\",\n",
    "                        retrieved_contexts=components[\"retrieved_contexts\"],\n",
    "                        # Add metadata for tool evaluation\n",
    "                        metadata={\n",
    "                            \"tool_usages\": components[\"tool_usages\"],\n",
    "                            \"available_tools\": components[\"available_tools\"],\n",
    "                            \"tool_info\": tool_info\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "                trace_sample_mapping.append({\n",
    "                    \"trace_id\": trace.id, \n",
    "                    \"type\": \"single_turn\", \n",
    "                    \"index\": len(single_turn_samples)-1\n",
    "                })\n",
    "            \n",
    "            # For regular conversation (single or multi-turn)\n",
    "            else:\n",
    "                messages = []\n",
    "                for i in range(max(len(components[\"user_inputs\"]), len(components[\"agent_responses\"]))):\n",
    "                    if i < len(components[\"user_inputs\"]):\n",
    "                        messages.append({\"role\": \"user\", \"content\": components[\"user_inputs\"][i]})\n",
    "                    if i < len(components[\"agent_responses\"]):\n",
    "                        messages.append({\n",
    "                            \"role\": \"assistant\", \n",
    "                            \"content\": components[\"agent_responses\"][i] + \"\\n\\n\" + tool_info\n",
    "                        })\n",
    "                \n",
    "                multi_turn_samples.append(\n",
    "                    MultiTurnSample(\n",
    "                        user_input=messages,\n",
    "                        metadata={\n",
    "                            \"tool_usages\": components[\"tool_usages\"],\n",
    "                            \"available_tools\": components[\"available_tools\"]\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "                trace_sample_mapping.append({\n",
    "                    \"trace_id\": trace.id, \n",
    "                    \"type\": \"multi_turn\", \n",
    "                    \"index\": len(multi_turn_samples)-1\n",
    "                })\n",
    "    \n",
    "    return {\n",
    "        \"single_turn_samples\": single_turn_samples,\n",
    "        \"multi_turn_samples\": multi_turn_samples,\n",
    "        \"trace_sample_mapping\": trace_sample_mapping\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "#### í‰ê°€ í•¨ìˆ˜ ì„¤ì •\n",
    "\n",
    "ë‹¤ìŒìœ¼ë¡œ ì¼ë¶€ ì§€ì› í‰ê°€ í•¨ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rag_samples(single_turn_samples, trace_sample_mapping):\n",
    "    \"\"\"Evaluate RAG-based samples and push scores to Langfuse\"\"\"\n",
    "    if not single_turn_samples:\n",
    "        print(\"No single-turn samples to evaluate\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Evaluating {len(single_turn_samples)} single-turn samples with RAG metrics\")\n",
    "    rag_dataset = EvaluationDataset(samples=single_turn_samples)\n",
    "    rag_results = evaluate(\n",
    "        dataset=rag_dataset,\n",
    "        metrics=[context_relevance, response_groundedness]\n",
    "    )\n",
    "    rag_df = rag_results.to_pandas()\n",
    "    \n",
    "    # Push RAG scores back to Langfuse\n",
    "    for mapping in trace_sample_mapping:\n",
    "        if mapping[\"type\"] == \"single_turn\":\n",
    "            sample_index = mapping[\"index\"]\n",
    "            trace_id = mapping[\"trace_id\"]\n",
    "            \n",
    "            if sample_index < len(rag_df):\n",
    "                # Use actual column names from DataFrame\n",
    "                for metric_name in rag_df.columns:\n",
    "                    if metric_name not in ['user_input', 'response', 'retrieved_contexts']:\n",
    "                        try:\n",
    "                            metric_value = float(rag_df.iloc[sample_index][metric_name])\n",
    "                            langfuse.create_score(\n",
    "                                trace_id=trace_id,\n",
    "                                name=f\"rag_{metric_name}\",\n",
    "                                value=metric_value\n",
    "                            )\n",
    "                            print(f\"Added score rag_{metric_name}={metric_value} to trace {trace_id}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error adding RAG score: {e}\")\n",
    "    \n",
    "    return rag_df\n",
    "\n",
    "def evaluate_conversation_samples(multi_turn_samples, trace_sample_mapping):\n",
    "    \"\"\"Evaluate conversation-based samples and push scores to Langfuse\"\"\"\n",
    "    if not multi_turn_samples:\n",
    "        print(\"No multi-turn samples to evaluate\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Evaluating {len(multi_turn_samples)} multi-turn samples with conversation metrics\")\n",
    "    conv_dataset = EvaluationDataset(samples=multi_turn_samples)\n",
    "    conv_results = evaluate(\n",
    "        dataset=conv_dataset,\n",
    "        metrics=[\n",
    "            request_completeness, \n",
    "            recommendations,\n",
    "            brand_tone,\n",
    "            tool_usage_effectiveness,\n",
    "            tool_selection_appropriateness\n",
    "        ]\n",
    "        \n",
    "    )\n",
    "    conv_df = conv_results.to_pandas()\n",
    "    \n",
    "    # Push conversation scores back to Langfuse\n",
    "    for mapping in trace_sample_mapping:\n",
    "        if mapping[\"type\"] == \"multi_turn\":\n",
    "            sample_index = mapping[\"index\"]\n",
    "            trace_id = mapping[\"trace_id\"]\n",
    "            \n",
    "            if sample_index < len(conv_df):\n",
    "                for metric_name in conv_df.columns:\n",
    "                    if metric_name not in ['user_input']:\n",
    "                        try:\n",
    "                            metric_value = float(conv_df.iloc[sample_index][metric_name])\n",
    "                            if pd.isna(metric_value):\n",
    "                                metric_value = 0.0\n",
    "                            langfuse.create_score(\n",
    "                                trace_id=trace_id,\n",
    "                                name=metric_name,\n",
    "                                value=metric_value\n",
    "                            )\n",
    "                            print(f\"Added score {metric_name}={metric_value} to trace {trace_id}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error adding conversation score: {e}\")\n",
    "    \n",
    "    return conv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-35",
   "metadata": {},
   "source": [
    "#### ë°ì´í„° ì €ì¥\n",
    "\n",
    "ë§ˆì§€ë§‰ìœ¼ë¡œ ë°ì´í„°ë¥¼ `CSV` í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“¤ê² ìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_csv(rag_df=None, conv_df=None, output_dir=\"evaluation_results\"):\n",
    "    \"\"\"Save evaluation results to CSV files\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    if rag_df is not None and not rag_df.empty:\n",
    "        rag_file = os.path.join(output_dir, f\"rag_evaluation_{timestamp}.csv\")\n",
    "        rag_df.to_csv(rag_file, index=False)\n",
    "        print(f\"RAG evaluation results saved to {rag_file}\")\n",
    "        results[\"rag_file\"] = rag_file\n",
    "    \n",
    "    if conv_df is not None and not conv_df.empty:\n",
    "        conv_file = os.path.join(output_dir, f\"conversation_evaluation_{timestamp}.csv\")\n",
    "        conv_df.to_csv(conv_file, index=False)\n",
    "        print(f\"Conversation evaluation results saved to {conv_file}\")\n",
    "        results[\"conv_file\"] = conv_file\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "#### ë©”ì¸ í‰ê°€ í•¨ìˆ˜ ìƒì„±\n",
    "\n",
    "ì´ì œ Langfuseì—ì„œ ì¶”ì ì„ ê°€ì ¸ì˜¤ê³ , ì²˜ë¦¬í•˜ê³ , Ragas í‰ê°€ë¥¼ ì‹¤í–‰í•˜ê³ , ì ìˆ˜ë¥¼ Langfuseë¡œ ë‹¤ì‹œ í‘¸ì‹œí•˜ëŠ” ë©”ì¸ í•¨ìˆ˜ë¥¼ ë§Œë“¤ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_traces(batch_size=10, lookback_hours=24, tags=None, save_csv=False):\n",
    "    \"\"\"Main function to fetch traces, evaluate them with RAGAS, and push scores back to Langfuse\"\"\"\n",
    "    # Fetch traces from Langfuse\n",
    "    traces = fetch_traces(batch_size, lookback_hours, tags)\n",
    "    \n",
    "    if not traces:\n",
    "        print(\"No traces found. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Process traces into samples\n",
    "    processed_data = process_traces(traces)\n",
    "    \n",
    "    # Evaluate the samples\n",
    "    rag_df = evaluate_rag_samples(\n",
    "        processed_data[\"single_turn_samples\"], \n",
    "        processed_data[\"trace_sample_mapping\"]\n",
    "    )\n",
    "    \n",
    "    conv_df = evaluate_conversation_samples(\n",
    "        processed_data[\"multi_turn_samples\"], \n",
    "        processed_data[\"trace_sample_mapping\"]\n",
    "    )\n",
    "    \n",
    "    # Save results to CSV if requested\n",
    "    if save_csv:\n",
    "        save_results_to_csv(rag_df, conv_df)\n",
    "    \n",
    "    return {\n",
    "        \"rag_results\": rag_df,\n",
    "        \"conversation_results\": conv_df\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    results = evaluate_traces(\n",
    "        lookback_hours=2,\n",
    "        batch_size=20,\n",
    "        tags=[\"Agent-SDK\"],\n",
    "        save_csv=True\n",
    "    )\n",
    "    \n",
    "    # Access results if needed for further analysis\n",
    "    if results:\n",
    "        if \"rag_results\" in results and results[\"rag_results\"] is not None:\n",
    "            print(\"\\nRAG Evaluation Summary:\")\n",
    "            print(results[\"rag_results\"].describe())\n",
    "            \n",
    "        if \"conversation_results\" in results and results[\"conversation_results\"] is not None:\n",
    "            print(\"\\nConversation Evaluation Summary:\")\n",
    "            print(results[\"conversation_results\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ì´ í‰ê°€ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•œ í›„:\n",
    "\n",
    "- Langfuse ëŒ€ì‹œë³´ë“œë¥¼ í™•ì¸í•˜ì—¬ í‰ê°€ ì ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”\n",
    "- ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ì—ì´ì „íŠ¸ ì„±ëŠ¥ì˜ ì¶”ì„¸ë¥¼ ë¶„ì„í•˜ì„¸ìš”\n",
    "- Strand ì—ì´ì „íŠ¸ë¥¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ì—¬ ì—ì´ì „íŠ¸ ì‘ë‹µì˜ ê°œì„  ì˜ì—­ì„ ì‹ë³„í•˜ì„¸ìš”\n",
    "- ë‚®ì€ ì ìˆ˜ì˜ ìƒí˜¸ ì‘ìš©ì— ëŒ€í•œ ìë™ ì•Œë¦¼ ì„¤ì •ì„ ê³ ë ¤í•˜ì„¸ìš”. ì •ê¸°ì ì¸ í‰ê°€ ì‘ì—…ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•´ cron ì‘ì—… ë˜ëŠ” ê¸°íƒ€ ì´ë²¤íŠ¸ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-41",
   "metadata": {},
   "source": [
    "## ì •ë¦¬\n",
    "\n",
    "ì•„ë˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ DynamoDB ì¸ìŠ¤í„´ìŠ¤ ë° Amazon Bedrock Knowledge Baseë¥¼ ì œê±°í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sh cleanup.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
